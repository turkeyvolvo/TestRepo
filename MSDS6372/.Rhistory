g
#Michael Smith: You can also use dirname(sys.frame(1)$ofile) to get the directory of the
#currently executing file so when someone runts knitr on the makefile, it should let you
#set a dynamic working directory relative to the makefile
library(downloader)
library(plyr)
library(questionr)
library(ggplot2)
download("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="GDP.csv")
download("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", destfile = "educationbycountry.csv")
#data starts at row 6 with blank row between header and data
gdpdata <- read.csv("GDP.csv", skip = 5, header = FALSE)
#keep raw data file for backup
gdpraw <- gdpdata
#only keep needed columns "countrycode", "economy", and "millions of US dollars"
gdpdata <- gdpdata[c(1,4,5)]
#only keep needed rows
gdpdata <- gdpdata[1:190,]
#assign names
names(gdpdata) <- c("countrycode", "country", "gdp")
#need to change gdp to numeric
gdpdata$gdp <- as.numeric(gsub(",", "", gdpdata$gdp))
#read in second data set
educdata <- read.csv("educationbycountry.csv", header = TRUE)
#keep raw data file for backup
educraw <- educdata
#only keep needed columns "CountryCode", "Long Name", "Income Group"
educdata <- educdata[c(1,2,3)]
#update names to match gdp data set
names(educdata) <- c("countrycode", "longname", "incomegroup")
#find nas
freq.na(gdpdata)
freq.na(educdata)
gdp.by.income <- merge(gdpdata, educdata, by="countrycode")
str(gdp.by.income)
#sort data frame by gdp in ascending order
gdp.by.income <- gdp.by.income[order(gdp.by.income$gdp),]
#subset HI:nonOECD countries and find mean
HInonOECD <- gdp.by.income[which(gdp.by.income$incomegroup== "High income: nonOECD"),]
mean(HInonOECD$gdp)
#subset HI:OECD countries and find mean
HIOECD <- gdp.by.income[which(gdp.by.income$incomegroup=="High income: OECD"),]
mean(HIOECD$gdp)
#explore the data
qplot(log(gdp.by.income$gdp), data=gdp.by.income, geom="density", fill=gdp.by.income$incomegroup, alpha=I(.5),main = "Distribution of GDP by Income Group", xlab = "GDP", ylab = "Density")
ggplot(gdp.by.income, aes(log(gdp.by.income$gdp), gdp.by.income$incomegroup)) + xlab("GDP") + ylab("Income Group")+ ggtitle("Heat Map of GDP by Income Group")+geom_bin2d()
#add a new column to divide countries into quantiles
ApplyQuantiles <- within(gdp.by.income, quantile <- as.integer(cut(gdp.by.income$gdp, quantile(gdp.by.income$gdp, (0:5/5)), include.lowest=TRUE, labels = FALSE)))
#see how many Lower middle Income countries are in each quantile
freq(quant.by.income$Quantile[which(quant.by.income$Income.Group=="Lower middle income")])
#visualize the income groups by quantile
#assign a ggplot to be "jittered" to variable "g"
g <- ggplot(quant.by.income, aes(x=quant.by.income$Quantile, y=quant.by.income$Income.Group)) + xlab("Quantile") + ylab("Income Group") + ggtitle("Plot of Income Groups According to Quantile") + theme(legend.position="none")
#add jitter points to the "g" ggplot
g+geom_jitter(aes(color=quant.by.income$Income.Group), position = position_jitter(width = .2))
#Michael Smith: You can also use dirname(sys.frame(1)$ofile) to get the directory of the
#currently executing file so when someone runts knitr on the makefile, it should let you
#set a dynamic working directory relative to the makefile
library(downloader)
library(plyr)
library(questionr)
library(ggplot2)
download("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="GDP.csv")
download("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", destfile = "educationbycountry.csv")
#data starts at row 6 with blank row between header and data
gdpdata <- read.csv("GDP.csv", skip = 5, header = FALSE)
#keep raw data file for backup
gdpraw <- gdpdata
#only keep needed columns "countrycode", "economy", and "millions of US dollars"
gdpdata <- gdpdata[c(1,4,5)]
#only keep needed rows
gdpdata <- gdpdata[1:190,]
#assign names
names(gdpdata) <- c("countrycode", "country", "gdp")
#need to change gdp to numeric
gdpdata$gdp <- as.numeric(gsub(",", "", gdpdata$gdp))
#read in second data set
educdata <- read.csv("educationbycountry.csv", header = TRUE)
#keep raw data file for backup
educraw <- educdata
#only keep needed columns "CountryCode", "Long Name", "Income Group"
educdata <- educdata[c(1,2,3)]
#update names to match gdp data set
names(educdata) <- c("countrycode", "longname", "incomegroup")
#find nas
freq.na(gdpdata)
freq.na(educdata)
gdp.by.income <- merge(gdpdata, educdata, by="countrycode")
str(gdp.by.income)
#sort data frame by gdp in ascending order
gdp.by.income <- gdp.by.income[order(gdp.by.income$gdp),]
#subset HI:nonOECD countries and find mean
HInonOECD <- gdp.by.income[which(gdp.by.income$incomegroup== "High income: nonOECD"),]
mean(HInonOECD$gdp)
#subset HI:OECD countries and find mean
HIOECD <- gdp.by.income[which(gdp.by.income$incomegroup=="High income: OECD"),]
mean(HIOECD$gdp)
#explore the data
qplot(log(gdp.by.income$gdp), data=gdp.by.income, geom="density", fill=gdp.by.income$incomegroup, alpha=I(.5),main = "Distribution of GDP by Income Group", xlab = "GDP", ylab = "Density")
ggplot(gdp.by.income, aes(log(gdp.by.income$gdp), gdp.by.income$incomegroup)) + xlab("GDP") + ylab("Income Group")+ ggtitle("Heat Map of GDP by Income Group")+geom_bin2d()
#add a new column to divide countries into quantiles
ApplyQuantiles <- within(gdp.by.income, quantile <- as.integer(cut(gdp.by.income$gdp, quantile(gdp.by.income$gdp, (0:5/5)), include.lowest=TRUE, labels = FALSE)))
#see how many Lower middle Income countries are in each quantile
quant.by.income <- data.frame("Quantile"=ApplyQuantiles$quantile,"Income Group"=ApplyQuantiles$incomegroup)
freq(quant.by.income$Quantile[which(quant.by.income$Income.Group=="Lower middle income")])
#visualize the income groups by quantile
#assign a ggplot to be "jittered" to variable "g"
g <- ggplot(quant.by.income, aes(x=quant.by.income$Quantile, y=quant.by.income$Income.Group)) + xlab("Quantile") + ylab("Income Group") + ggtitle("Plot of Income Groups According to Quantile") + theme(legend.position="none")
#add jitter points to the "g" ggplot
g+geom_jitter(aes(color=quant.by.income$Income.Group), position = position_jitter(width = .2))
CER <- 0.2
d <- 0.2
d<- 4
(pmorm(d+qnorm(CER))-CER)
(pnorm(d+qnorm(CER))-CER)
d<- 10
(pnorm(d+qnorm(CER))-CER)
d<- 100
(pnorm(d+qnorm(CER))-CER)
d<- 900
(pnorm(d+qnorm(CER))-CER)
d<- 1000000
(pnorm(d+qnorm(CER))-CER)
d<- .5
(pnorm(d+qnorm(CER))-CER)
CER <- 1
(pnorm(d+qnorm(CER))-CER)
d<-4
(pnorm(d+qnorm(CER))-CER)
CER <- 20
library(xml2)
library(XML)
fileURL <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal=TRUE)
rootNode <- xmlRoot(doc)
rootNode
names(rootNode)
rootNode[[1][1]]
rootNode[[1]][[1]]
xmlSApply(rootNode, xmlValue)
xpathSApply(rootNode, "//name", xmlValue)
xpathSApply(rootNode, "//price", xmlValue)
library(ISLR)
install.packages("islr")
install.packages("ISLR")
library(ISLR)
library(ISLR)
install.packages("MASS")
library(MASS)
library(ISLR)
library(MASS)
setwd("~/testrepo/MSDS6372")
library(MASS)
library(klaR)
library(caret)
library(formattable)
install.packages("formattable")
library(formattable)
cancerdata.raw <- read.csv("cancerdata.csv", header = TRUE)
summary(cancerdata.raw)
str(cancerdata.raw)
train <- cancerdata.raw[sample(nrow(cancerdata.raw), round(nrow(cancerdata.raw)/2 ,0)), ]
testRows <- !(cancerdata.raw$id %in% train$id)
??!
!
)
test <- cancerdata.raw[testRows,]
# run wilkes lambda stepwise variable selection
VariableSelect <- greedy.wilks(diagnosis ~  radius_mean  +
texture_mean            +
perimeter_mean          +
area_mean               +
smoothness_mean         +
compactness_mean        +
concavity_mean          +
concave.points_mean     +
symmetry_mean           +
fractal_dimension_mean  +
radius_se               +
texture_se              +
perimeter_se            +
area_se                 +
smoothness_se           +
compactness_se          +
concavity_se            +
concave.points_se       +
symmetry_se             +
fractal_dimension_se    +
radius_worst            +
texture_worst           +
perimeter_worst         +
area_worst              +
smoothness_worst        +
compactness_worst       +
concavity_worst         +
concave.points_worst    +
symmetry_worst          +
fractal_dimension_worst
,data = cancerdata.raw
,niveau = 0.05)
lda.fit <- lda(VariableSelect$formula, data=train)
lda.fit
names(lda.predict)
lda.predict <- predict(lda.fit, data=test)
## predict class
lda.class <- predict(lda.fit, test)$class
##see what's available from the predict call
names(lda.predict)
##table the results of the predictions compared to the real diagnoses
table(lda.class, test$diagnosis)
LDA.Accuracy <- mean(lda.class==test$diagnosis)
#use a different threshold of 90%
sum(lda.predict$posterior[,1]>0.9)
##QDA
qda.fit <- qda(VariableSelect$formula, data=train)
qda.fit
##predict class
qda.class <- predict(qda.fit, test)$class
table(qda.class, test$diagnosis)
##test for accuracy
QDA.Accuracy <- mean(qda.class == test$diagnosis)
modelFitQDA <- train(VariableSelect$formula, method='qda', c('scale', 'center'), data=train)
modelFitQDA
modelFitLDA <- train(VariableSelect$formula, method='lda', c('scale', 'center'), data=train)
modelFitLDA
confusionMatrix(test$diagnosis, predict(modelFitQDA, test))
confusionMatrix(test$diagnosis, predict(modelFitLDA, test))
cov(test)
test
testRows
cov(test, use = "complete")
cov(cancerdata.raw, use = "complete")
str(cancerdata.raw)
str(test)
str(VariableSelect)
VariableSelect
VariableSelect$formula
lda.predict
cov(test$radius_mean, test$texture_mean)
str(test)
covmatrix <- matrix(data=cancerdata.raw)
str(covmatrix)
cov(cancerdata.raw)
cov(cancerdata.raw, use = "complete")
matrix(test[3,], test[,3])
str(test)
mydata.mat <- as.matrix(test[,-1:2])
names(VariableSelect$formula)
VariableSelect$formula
VariableSelect
names(VariableSelect$vars)
VariableSelect$vars
str(test)
matrix(hist(train))
hist(cancerdata.raw)
hist(cancerdata.raw$diagnosis)
hist(as.numeric(cancerdata.raw$diagnosis))
matrix(hist(cancerdata.raw$radius_mean ~ cancerdata.raw$fractal_dimension_worst))
matrix(hist(cancerdata.raw[3:32]))
matrix(hist(cancerdata.raw$radius_mean)
)
par(14,14)
par(mfrow=c(14,14))
hist(cancerdata.raw$radius_mean)
par(mfrow=c(3,3))
hist(cancerdata.raw$radius_mean)
hist(cancerdata.raw$texture_mean)
matrix(hist(cancerdata.raw$radius_mean ~ .))
train <- cancerdata.raw[sample(nrow(cancerdata.raw), round(nrow(cancerdata.raw)/2 ,0)), ]
testRows <- !(cancerdata.raw$id %in% train$id)
test <- cancerdata.raw[testRows,]
# run wilkes lambda stepwise variable selection
VariableSelect <- greedy.wilks(diagnosis ~  radius_mean  +
texture_mean            +
perimeter_mean          +
area_mean               +
smoothness_mean         +
compactness_mean        +
concavity_mean          +
concave.points_mean     +
symmetry_mean           +
fractal_dimension_mean  +
radius_se               +
texture_se              +
perimeter_se            +
area_se                 +
smoothness_se           +
compactness_se          +
concavity_se            +
concave.points_se       +
symmetry_se             +
fractal_dimension_se    +
radius_worst            +
texture_worst           +
perimeter_worst         +
area_worst              +
smoothness_worst        +
compactness_worst       +
concavity_worst         +
concave.points_worst    +
symmetry_worst          +
fractal_dimension_worst
,data = cancerdata.raw
,niveau = 0.05)
VariableSelect
lda.fit <- lda(VariableSelect$formula, data=train)
lda.fit
lda.predict <- predict(lda.fit, data=test)
## predict class
lda.class <- predict(lda.fit, test)$class
##see what's available from the predict call
names(lda.predict)
##table the results of the predictions compared to the real diagnoses
table(lda.class, test$diagnosis)
LDA.Accuracy <- mean(lda.class==test$diagnosis)
##QDA
qda.fit <- qda(VariableSelect$formula, data=train)
qda.fit
##predict class
qda.class <- predict(qda.fit, test)$class
table(qda.class, test$diagnosis)
##test for accuracy
QDA.Accuracy <- mean(qda.class == test$diagnosis)
modelFitQDA <- train(VariableSelect$formula, method='qda', c('scale', 'center'), data=train)
modelFitQDA
modelFitLDA <- train(VariableSelect$formula, method='lda', c('scale', 'center'), data=train)
modelFitLDA
confusionMatrix(test$diagnosis, predict(modelFitQDA, test))
par(mfrow=c(3,2))
lda.fit
plot(lda.class, main = "Predicted LDA Test Data")
LDA.Accuracy <- mean(lda.class==test$diagnosis)
LDA.Accuracy
confusionMatrix(test$diagnosis, predict(modelFitLDA, test))
plot(lda.class, main = "Predicted LDA Test Data")
plot(qda.class, main = "Predicted QDA Test Data") ##qda graph - what does it mean
confusionMatrix(test$diagnosis, predict(modelFitQDA, test))
str(cancerdata.raw)
par(mfrow=(3,3))
par(mfrow=c(3,2))
hist(cancerdata.raw$concave.points_worst)
hist(cancerdata.raw$radius_worst)
hist(cancerdata.raw$texture_worst)
hist(cancerdata.raw$area_worst)
hist(cancerdata.raw$smoothness_se)
hist(cancerdata.raw$symmetry_worst)
hist(cancerdata.raw$compactness_se)
hist(cancerdata.raw$radius_se)
hist(cancerdata.raw$fractal_dimension_worst)
hist(cancerdata.raw$compactness_mean)
hist(cancerdata.raw$concave.points_mean)
hist(cancerdata.raw$concavity_worst)
hist(cancerdata.raw$concavity_se)
hist(cancerdata.raw$area_se)
hist(log(cancerdata.raw$concave.points_worst))
hist(log(cancerdata.raw$radius_worst))
cov(cancerdata.raw$radius_worst)
cov(cancerdata.raw$concave.points_worst, cancerdata.raw$radius_worst)
cov(log(cancerdata.raw$concave.points_worst), log(cancerdata.raw$radius_worst)
)
